{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as R\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "import gc\n",
    "\n",
    "pid = os.getpid()\n",
    "py = psutil.Process(pid)\n",
    "\n",
    "print(py.memory_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing reshape to find GetIndex function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[1, 2], [3, 4]], [[5, 6], [7, 8]]])\n",
    "print(a,'\\n')\n",
    "print(a[0],'\\n')\n",
    "print(a[0,0],'\\n')\n",
    "print(a[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nx = 3\n",
    "ny = 4\n",
    "nz = 5\n",
    "b = np.arange(nx*ny*nz)\n",
    "print(b)\n",
    "c = b.reshape(nx,ny,nz)\n",
    "print(c)\n",
    "# print(c[0,0,0])#z,y,x\n",
    "print(c[1,0,0])#z\n",
    "print(c[0,1,0])#y\n",
    "print(c[0,0,1])#x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(ix,iy,iz,nx,ny,nz):\n",
    "    part_tau_direction = nz*iy\n",
    "    part_pf_direction  = iz\n",
    "    part_fe_direction  = nz*ny*ix\n",
    "    return part_fe_direction + part_pf_direction + part_tau_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix,iy,iz = 2,3,4\n",
    "print(c[ix,iy,iz])\n",
    "print(b[find_index(ix,iy,iz,nx,ny,nz)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data with header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ROOT as R\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the kernel dies by running the next line, run this line in a separate .py in the terminal. This will show you the errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R.gInterpreter.ProcessLine('#include \"DataLoader.h\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tau = 10\n",
    "n_pf  = 5\n",
    "n_fe  = 30\n",
    "n_counts = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = R.DataLoader('/data/store/reco_skim_v1/tau_DYJetsToLL_M-50.root', n_tau)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_loader.LoadNext()\n",
    "n_batches = data_loader.NumberOfBatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    while True:\n",
    "        data_loader.Reset()\n",
    "        while data_loader.HasNext():\n",
    "            data = data_loader.LoadNext()\n",
    "            x_np = np.asarray(data.x)\n",
    "            x_3d = x_np.reshape((n_tau, n_pf, n_fe))\n",
    "            y_np = np.asarray(data.y)\n",
    "            y_2d = y_np.reshape((n_tau, n_counts))\n",
    "            yield x_3d, y_2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some tests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.asarray(data.x)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fe  = 3\n",
    "n_tau = 4\n",
    "n_pf  = 2\n",
    "x_3d = x_np.reshape((n_tau, n_pf, n_fe))\n",
    "print(x_3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_3d[1, 1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 1\n",
    "f = 9\n",
    "print(type((d,f)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x,y) = next(generator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((x,y),'\\n')\n",
    "print((x[0,0,:],y[0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[1,0],[0., 0.],[0., 1.],[0., 0.],[0., 1.],[0., 0.],[0., 1.],[0., 0.],[0., 1.],[0., 0.]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(n_pf,n_fe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inputs = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = tf.keras.layers.Dense(2, activation=tf.nn.relu)(x_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fit(\n",
    "    x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None,\n",
    "    validation_split=0.0, validation_data=None, shuffle=True, class_weight=None,\n",
    "    sample_weight=None, initial_epoch=0, steps_per_epoch=None,\n",
    "    validation_steps=None, validation_batch_size=None, validation_freq=1,\n",
    "    max_queue_size=10, workers=1, use_multiprocessing=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x = tf.data.Dataset.from_generator(generator,(tf.float32, tf.float32),(tf.TensorShape([None,5,30]), tf.TensorShape([None,2]))), epochs = 1, steps_per_epoch = n_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement model as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super(MyModel, self).__init__()\n",
    "    self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "    self.dense2 = tf.keras.layers.Dense(2, activation=tf.nn.relu)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x_inputs = self.dense1(inputs2)\n",
    "    return self.dense2(x_inputs)\n",
    "\n",
    "model2 = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(x = generator,epochs = 1, steps_per_epoch = n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/02\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ROOT as R\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "R.gInterpreter.ProcessLine('#include \"DataLoader.h\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tau = 10\n",
    "n_pf  = 2\n",
    "n_fe  = 2\n",
    "n_counts = 2\n",
    "n_epochs = 10\n",
    "\n",
    "data_loader = R.DataLoader('/data/store/reco_skim_v1/tau_DYJetsToLL_M-50.root', n_tau, 0, 1000)\n",
    "data = data_loader.LoadNext()\n",
    "n_batches = data_loader.NumberOfBatches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator():\n",
    "    while True:\n",
    "        data_loader.Reset()\n",
    "        while data_loader.HasNext():\n",
    "            data = data_loader.LoadNext()\n",
    "            x_np = np.asarray(data.x)\n",
    "            x_3d = x_np.reshape((n_tau, n_pf, n_fe))\n",
    "            y_np = np.asarray(data.y)\n",
    "            y_2d = y_np.reshape((n_tau, n_counts))\n",
    "            yield x_3d, y_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metrics(history, n_epochs):\n",
    "    epochs = history.epoch\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    mse = hist[\"mae\"]\n",
    "    acc = hist[\"accuracy\"]\n",
    "\n",
    "    fig, axes = plt.subplots(2, sharex=False, figsize=(12, 8))\n",
    "    fig.suptitle('Training Metrics')\n",
    "    axes[0].set_ylabel(\"Loss\", fontsize=14)\n",
    "    axes[0].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    axes[0].set_xticks(np.arange(0, n_epochs, 1.0))\n",
    "    axes[0].plot(epochs, mse, 'bo', label=\"Loss\")\n",
    "    axes[1].set_ylabel(\"Accuracy\", fontsize=14)\n",
    "    axes[1].set_xlabel(\"Epoch\", fontsize=14)\n",
    "    axes[1].set_xticks(np.arange(0, n_epochs, 1.0))\n",
    "    axes[1].plot(epochs, acc, 'ro', label=\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model construction:\n",
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten() #flattens a ND array to a 2D array\n",
    "        self.dense1 = tf.keras.layers.Dense(4, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(2, activation=tf.nn.relu)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        return self.dense2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mae\",\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x = tf.data.Dataset.from_generator(generator,\\\n",
    "                                            (tf.float32, tf.float32),\\\n",
    "                                            (tf.TensorShape([None,n_pf,n_fe]), tf.TensorShape([None,n_counts]))), \\\n",
    "                                            epochs = n_epochs, steps_per_epoch = n_batches)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metrics(history, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model with a test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = R.DataLoader('/data/store/reco_skim_v1/tau_DYJetsToLL_M-50.root', n_tau,1000,1100)\n",
    "data = data_loader.LoadNext()\n",
    "n_batches = data_loader.NumberOfBatches()\n",
    "\n",
    "model.evaluate(x = tf.data.Dataset.from_generator(generator,\\\n",
    "                                                (tf.float32,tf.float32),\\\n",
    "                                                (tf.TensorShape([None,n_pf,n_fe]),tf.TensorShape([None,n_counts]))),\\\n",
    "                                                   steps = n_batches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_test():\n",
    "    while True:\n",
    "        data_loader.Reset()\n",
    "        while data_loader.HasNext():\n",
    "            data = data_loader.LoadNext()\n",
    "            x_np = np.asarray(data.x)\n",
    "            x_3d = x_np.reshape((n_tau, n_pf, n_fe))\n",
    "            yield x_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x = tf.data.Dataset.from_generator(generator_test,(tf.float32),\\\n",
    "                                                        (tf.TensorShape([None,n_pf,n_fe]))),steps=1)\n",
    "#print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(x = tf.data.Dataset.from_generator(generator,\\\n",
    "                                            (tf.float32, tf.float32),\\\n",
    "                                            (tf.TensorShape([None,n_pf,n_fe]), tf.TensorShape([None,n_counts]))), \\\n",
    "                                            steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_test_labels():\n",
    "    while True:\n",
    "        data_loader.Reset()\n",
    "        while data_loader.HasNext():\n",
    "            data = data_loader.LoadNext()\n",
    "            y_np = np.asarray(data.y)\n",
    "            y_2d = y_np.reshape((n_tau, n_counts))\n",
    "            yield y_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test, labels = next(generator())\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(next(generator_test_labels()))\n",
    "labels = next(generator_test_labels())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_range = -5.5\n",
    "max_range = 5.5\n",
    "n_bins = int(max_range-min_range)\n",
    "\n",
    "H0,edges,patches = plt.hist(labels[:,0]-pred[:,0], bins=11, range=(min_range,max_range), \\\n",
    "                        facecolor='red', alpha=0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.xticks(np.arange(min_range+0.5, max_range+0.5, 1.0))\n",
    "plt.xlabel('Charged count difference')\n",
    "plt.ylabel('Number of entries')\n",
    "plt.show()\n",
    "\n",
    "H0,edges,patches = plt.hist(labels[:,1]-pred[:,1], bins=n_bins, range=(min_range,max_range), \\\n",
    "                        facecolor='blue', alpha=0.5, edgecolor='black', linewidth=1.2)\n",
    "plt.xticks(np.arange(min_range+0.5, max_range+0.5, 1.0))\n",
    "plt.xlabel('Neutral count difference')\n",
    "plt.ylabel('Number of entries')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = np.linspace(0,6,7)\n",
    "H0,a,b  = np.histogram2d(labels[:,0], pred[:,0],bins=(edges, edges)) #x,y\n",
    "H1,a,b  = np.histogram2d(labels[:,1], pred[:,1],bins=(edges, edges)) #x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(H0, cmap='YlGnBu', annot=True, fmt=\"3.0f\")\n",
    "plt.ylim(0,6)\n",
    "plt.xlim(0,6)\n",
    "plt.ylabel('True charge counts',fontsize = 16)\n",
    "plt.xlabel('Predicted charge counts',fontsize = 16)\n",
    "plt.show()\n",
    "\n",
    "fig2 = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(H1, cmap='YlGnBu', annot=True, fmt=\"3.0f\")\n",
    "plt.ylim(0,6)\n",
    "plt.xlim(0,6)\n",
    "plt.ylabel('True neutral counts',fontsize = 16)\n",
    "plt.xlabel('Predicted neutral counts',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4D histogram -> confusion matrix filling -> accurcy extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.22/02\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import ROOT as R\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1,0,1],[0,1,1]])\n",
    "print(a.shape)\n",
    "print('a: ',a)\n",
    "H, edges = np.histogramdd(a, bins = (2,2,2))\n",
    "print(H[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.random.randn(100,4)\n",
    "print(r.shape)\n",
    "# print(r) #100 linee e 4 colonne\n",
    "H, edges = np.histogramdd(r, bins = (5, 8, 4, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(H)\n",
    "print('A ', H[:,0],'\\n')     #3x4\n",
    "print('B ', H[:,:,0],'\\n')   #2x4\n",
    "print('C ', H[:,:,:,0],'\\n') #2x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = plt.figure(figsize=(5,5))\n",
    "sns.heatmap(H[0], cmap='YlGnBu', annot=True, fmt=\"3.0f\")\n",
    "plt.ylim(0,6)\n",
    "plt.xlim(0,6)\n",
    "plt.ylabel('True neutral counts',fontsize = 16)\n",
    "plt.xlabel('Predicted neutral counts',fontsize = 16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(1,2**4+1,1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[ 1  2]\n",
      "   [ 3  4]]\n",
      "\n",
      "  [[ 5  6]\n",
      "   [ 7  8]]]\n",
      "\n",
      "\n",
      " [[[ 9 10]\n",
      "   [11 12]]\n",
      "\n",
      "  [[13 14]\n",
      "   [15 16]]]]\n",
      "(2, 2, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "a = a.reshape(2,2,2,2) #due blocconi di due matrici 2x2\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[14, 22],\n",
       "       [46, 54]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[:,0,:,0]+a[:,0,:,1]+a[:,1,:,0]+a[:,1,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [0. 0.]]\n",
      "0   0\n",
      "0   1\n",
      "1   0\n",
      "1   1\n",
      "[[14. 22.]\n",
      " [46. 54.]]\n"
     ]
    }
   ],
   "source": [
    "b = np.zeros((2,2))\n",
    "print(b)\n",
    "for i in range(0,2):\n",
    "    for j in range(0,2):\n",
    "        b += a[:,i,:,j]\n",
    "        print(i,' ',j)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('A: ', np.sum(a[0,0,:],axis=0)) # somma prima linea primo blocco\n",
    "# print('B: ', np.sum(a[0,:,0],axis=0)) # somma prima colonna primo blocco\n",
    "# print('C: ', np.sum(a[0,1,:],axis=0)) # somma seconda linea primo blocco\n",
    "# print('D: ', np.sum(a[0,:,1],axis=0)) # somma seconda colonna primo blocco\n",
    "print('E: ', np.sum(a[0,:,:,:],axis=0)) \n",
    "print('F: ', np.sum(a[0,:,:,:],axis=1)) \n",
    "print('E: ', np.sum(a[:,0,:,:],axis=0)) \n",
    "print('F: ', np.sum(a[:,0,:,:],axis=1)) \n",
    "print('E: ', np.sum(a[:,:,0,:],axis=0)) \n",
    "print('F: ', np.sum(a[:,:,0,:],axis=1)) \n",
    "print('E: ', np.sum(a[:,:,:,0],axis=0)) \n",
    "print('F: ', np.sum(a[:,:,:,0],axis=1)) \n",
    "print('E: ', np.sum(a[1,:,:,:],axis=0)) \n",
    "print('F: ', np.sum(a[1,:,:,:],axis=1)) \n",
    "print('E: ', np.sum(a[:,1,:,:],axis=0)) \n",
    "print('F: ', np.sum(a[:,1,:,:],axis=1)) \n",
    "print('E: ', np.sum(a[:,:,1,:],axis=0)) \n",
    "print('F: ', np.sum(a[:,:,1,:],axis=1)) \n",
    "print('E: ', np.sum(a[:,:,:,1],axis=0)) \n",
    "print('F: ', np.sum(a[:,:,:,1],axis=1)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physics performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = R.DataLoader('/data/store/reco_skim_v1/tau_DYJetsToLL_M-50.root', n_tau, 5000, 5500)\n",
    "n_batches   = data_loader.NumberOfBatches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = None\n",
    "dm_bins = np.arange(-0.5,23.5,1) \n",
    "n_steps = 2\n",
    "count_steps = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x,y in generator():\n",
    "    y_pred = model.predict(x)\n",
    "    yy = np.concatenate((y, y_pred), axis = 1)\n",
    "    h, _ = np.histogrmdd(yy, bins=[dm_bins, dm_bins, dm_bins, dm_bins])\n",
    "\n",
    "    if conf_matrix is None:\n",
    "        conf_matrix = h\n",
    "    else:\n",
    "        conf_matrix += h\n",
    "    \n",
    "    count_steps += 1\n",
    "\n",
    "    if count_steps >= n_steps: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
